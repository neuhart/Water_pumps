{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 342,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "outputs": [],
   "source": [
    "feature_filename = \"data/Features.csv\"\n",
    "label_filename = \"data/Labels.csv\"\n",
    "df_feat = pd.read_csv(feature_filename)\n",
    "df_label = pd.read_csv(label_filename)\n",
    "df = pd.merge(df_feat, df_label, on='id', how='inner')\n",
    "\n",
    "del df_feat\n",
    "del df_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop columns\n",
    "for more details on why these columns are dropped please refer to the data_understanding.ipynb / data_understanding2.ipynb file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.drop([\"date_recorded\", \"scheme_name\", \"num_private\", \"wpt_name\", \"subvillage\", \"ward\", \"public_meeting\", \"recorded_by\", \"permit\", \"extraction_type\",\"extraction_type_group\", \"scheme_management\", \"management_group\",\"payment\", \"water_quality\", \"quality_group\", \"quantity_group\", \"source_type\", \"waterpoint_type_group\"], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove outliers\n",
    "for more details on why I chose to remove these outliers and how I came up with the thresholds please refer to the data_understanding.ipynb file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "outputs": [],
   "source": [
    "df = df[df[\"amount_tsh\"] <= 120]\n",
    "df = df[df[\"population\"] <= 10000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Impute missing values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "outputs": [],
   "source": [
    "def median_imputer(df, ref_col, feat_ls, mis_values):\n",
    "    \"\"\"Imputes each instance with missing value (for each feature in the feat_ls list) with the median value\n",
    "    of instances grouped by the ref_col feature if possible\n",
    "    else: impute median value of column\n",
    "\n",
    "    :argument:\n",
    "        df(pd.Dataframe): pd.Dataframe containing the data\n",
    "        ref_col(str):  containing the reference column/feature\n",
    "        feat_ls(list): list of features that need to be imputed\n",
    "        mis_values(list): list containing the placeholder values for missing values (e.g.: 0, NaN) for each feature\n",
    "    \"\"\"\n",
    "\n",
    "    df_med = df.copy()\n",
    "    # Change missing values to NaN values so that they are not considered when computing the median\n",
    "    #for att,mv in zip(feat_ls,mis_values):\n",
    "        #df_med[att].mask(df[att] == mv, np.nan, inplace=True)\n",
    "\n",
    "    #Compute medians of df_med (grouped by our reference column of choice) for each attribute in feat_ls\n",
    "    df_med = df_med.groupby([ref_col])[feat_ls].median(numeric_only=True)\n",
    "\n",
    "    def impute(row):\n",
    "        for att in feat_ls:\n",
    "            row[att] = df_med.loc[row[ref_col]][att]\n",
    "        return row\n",
    "\n",
    "    for att, mv in zip(feat_ls,mis_values):\n",
    "        df.loc[df[att]==mv, att] = df[df[att]==mv].apply(impute, axis=1)[att]\n",
    "\n",
    "    # Now impute simple column median for those instances where we couldnt compute a median value of their corresponding ref_col group\n",
    "    for att in feat_ls:\n",
    "        df[att] =SimpleImputer(missing_values=np.NaN, strategy='median').fit_transform(df[[att]])\n",
    "\n",
    "median_imputer(df, \"district_code\", [\"gps_height\", \"population\", \"longitude\", \"latitude\"], [0,0, 0,-2.000000e-08])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "outputs": [],
   "source": [
    "imp_median = SimpleImputer(missing_values=0, strategy='median')\n",
    "df[\"construction_year\"] = imp_median.fit_transform(df[[\"construction_year\"]])\n",
    "df[\"amount_tsh\"] = imp_median.fit_transform(df[[\"amount_tsh\"]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reduce Categories\n",
    "\n",
    "We reduce the number of categories for some features. Some categories of a categorical attribute appear only few times and can therefore be disregarded to save computational cost."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [],
   "source": [
    "df[\"waterpoint_type\"].mask(df[\"waterpoint_type\"].isin([\"improved spring\", \"cattle trough\", \"dam\"]), \"other\", inplace=True)\n",
    "df[\"waterpoint_type\"].mask(df[\"waterpoint_type\"].isin([\"communal standpipe multiple\"]), \"communal standpipe\", inplace=True)\n",
    "df[\"source\"].mask(df[\"source\"].isin([\"other\"]), \"unknown\", inplace=True)\n",
    "df[\"payment_type\"].mask(df[\"payment_type\"].isin([\"other\"]), \"unknown\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Drop null values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [
    {
     "data": {
      "text/plain": "functional                 23040\nnon functional             19518\nfunctional needs repair     2929\nName: status_group, dtype: int64"
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"status_group\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### save cleaned dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [],
   "source": [
    "df.to_csv(\"data/cleaned_data.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}